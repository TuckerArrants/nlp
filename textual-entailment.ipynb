{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "XLM-R, Back-Translation TTA, MNLI.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TuckerArrants/nlp/blob/master/textual-entailment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTrZNeFEK-OP",
        "colab_type": "text"
      },
      "source": [
        "# It's Elementary, My Dear Watson\n",
        "\n",
        "**Natural Language Inference (NLI) is a specific type of NLP task where we must determine whether or not a hypothesis is true based on a premise. Specifically, given a pair of sentences, can we classify them into three different classes: 0 - entailment, 1 - contradiction, 2 - neutral?**\n",
        "\n",
        "**The current leading model in this field is RoBERTa, described by its creators as a 'robustly optimized BERT pretraining approach'. It changes some of the key hyperparameters of BERT and removes the next-sentece pretraining objective all together. The original paper can be found [here](https://arxiv.org/abs/1907.11692) and the source code [here](https://github.com/pytorch/fairseq/tree/master/examples/roberta)**\n",
        "\n",
        "**Now, we have 15 different languages in our dataset, so we cannot use the standard pre-trained RoBERTa model as it has only been trained on English sequences. Luckily, there is [XLM-RoBERTa](https://huggingface.co/transformers/model_doc/xlmroberta.html) (original paper can be found [here](https://arxiv.org/abs/1911.02116)) which has been trained on 2.5TB of filtered CommonCrawl data in 100 different languages. The implementation procedude is the same as RoBERTa's, so it is easy enough to deploy. Let's see how:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "IjZ816ZJK-OQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "120be752-b3a6-4c40-fd18-bc55f239ce6a"
      },
      "source": [
        "#python basics\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import math, os, re, time, random\n",
        "import numpy as np, pandas as pd, seaborn as sns\n",
        "\n",
        "#deep learning basics\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "#nlp augmentation\n",
        "!pip install --quiet googletrans\n",
        "from googletrans import Translator\n",
        "\n",
        "#model evaluation\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "\n",
        "#for fast parallel processing\n",
        "from dask import bag, diagnostics\n",
        "\n",
        "#easy way to shuffle rows\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "#ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "#get current TensorFlow version fo\n",
        "print(\"Currently using Tensorflow version \" + tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Currently using Tensorflow version 2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "grzgGBJ2K-OT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#choose devicve\n",
        "DEVICES = ['GPU', 'TPU']\n",
        "DEVICE = DEVICES[1]\n",
        "\n",
        "#choose number of epochs to train for\n",
        "EPOCHS = 10\n",
        "\n",
        "#choose seed\n",
        "SEED = 34\n",
        "\n",
        "#choose to see training progress or not\n",
        "VERBOSE = 2\n",
        "\n",
        "#choose maximum length of sequence inputs\n",
        "MAX_LEN = 75\n",
        "\n",
        "#choose learning rate for Adam optimizer\n",
        "LR_RATE = 1e-5\n",
        "\n",
        "#choose to generate augmented text data or not\n",
        "#False if loading from external dataset, as I am\n",
        "GEN_AUG = False \n",
        "\n",
        "#choose to add augmented text data in training\n",
        "ADD_AUG = False\n",
        "\n",
        "#choose to use external MNLI data in training\n",
        "ADD_MNLI = True\n",
        "\n",
        "#choose to use translated MNLU data in training\n",
        "ADD_XMNLI = True\n",
        "\n",
        "#choose to test on augmented datasets\n",
        "USE_TTA = False"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "5ZH001YeI9tN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seed_everything(seed):\n",
        "    os.environ['PYTHONHASHSEED']=str(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    \n",
        "seed_everything(SEED)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUdfpF_2K-OV",
        "colab_type": "text"
      },
      "source": [
        "# EDA\n",
        "\n",
        "**A very brief data exploration; I will expand this section in future iterations of the notebook**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "oE_xjcJNK-OW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "4d39a08e-64b3-4814-c87c-5e4e2a5e44ed"
      },
      "source": [
        "#get CSV files\n",
        "train = pd.read_csv(\"train.csv\")\n",
        "test = pd.read_csv(\"test.csv\")\n",
        "\n",
        "print(f'Train shape: {train.shape}')\n",
        "train.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train shape: (12120, 6)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>premise</th>\n",
              "      <th>hypothesis</th>\n",
              "      <th>lang_abv</th>\n",
              "      <th>language</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5130fd2cb5</td>\n",
              "      <td>and these comments were considered in formulat...</td>\n",
              "      <td>The rules developed in the interim were put to...</td>\n",
              "      <td>en</td>\n",
              "      <td>English</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5b72532a0b</td>\n",
              "      <td>These are issues that we wrestle with in pract...</td>\n",
              "      <td>Practice groups are not permitted to work on t...</td>\n",
              "      <td>en</td>\n",
              "      <td>English</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3931fbe82a</td>\n",
              "      <td>Des petites choses comme celles-l√† font une di...</td>\n",
              "      <td>J'essayais d'accomplir quelque chose.</td>\n",
              "      <td>fr</td>\n",
              "      <td>French</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5622f0c60b</td>\n",
              "      <td>you know they can't really defend themselves l...</td>\n",
              "      <td>They can't defend themselves because of their ...</td>\n",
              "      <td>en</td>\n",
              "      <td>English</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>86aaa48b45</td>\n",
              "      <td>‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡πà‡∏ô‡∏ö‡∏ó‡∏ö‡∏≤‡∏ó‡∏™‡∏°‡∏°‡∏∏‡∏ï‡∏¥‡∏Å‡πá‡πÄ‡∏ä‡πà‡∏ô‡∏Å‡∏±‡∏ô ‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÑ‡∏î‡πâ‡πÅ‡∏™‡∏î...</td>\n",
              "      <td>‡πÄ‡∏î‡πá‡∏Å‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏´‡πá‡∏ô‡πÑ‡∏î‡πâ‡∏ß‡πà‡∏≤‡∏ä‡∏≤‡∏ï‡∏¥‡∏û‡∏±‡∏ô‡∏ò‡∏∏‡πå‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£</td>\n",
              "      <td>th</td>\n",
              "      <td>Thai</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  ... label\n",
              "0  5130fd2cb5  ...     0\n",
              "1  5b72532a0b  ...     2\n",
              "2  3931fbe82a  ...     0\n",
              "3  5622f0c60b  ...     0\n",
              "4  86aaa48b45  ...     1\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "TXaVG-qQK-OY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "e0d458c4-5fef-4928-ef3c-0d529f7fc1bd"
      },
      "source": [
        "print(f'Test shape: {test.shape}')\n",
        "test.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test shape: (5195, 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>premise</th>\n",
              "      <th>hypothesis</th>\n",
              "      <th>lang_abv</th>\n",
              "      <th>language</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>c6d58c3f69</td>\n",
              "      <td>ÿ®⁄©ÿ≥ÿå ⁄©€åÿ≥€åÿå ÿ±ÿß€Å€åŸÑÿå €åÿ≥ÿπ€åÿß€Åÿå ⁄©€åŸÑ€åÿå ⁄©€åŸÑ€åÿå ÿßŸàÿ± ⁄©ŸàŸÑŸÖ...</td>\n",
              "      <td>⁄©€åÿ≥€å ⁄©€í ŸÑÿ¶€í ⁄©Ÿàÿ¶€å €åÿßÿØ⁄Øÿßÿ± ŸÜ€Å€å⁄∫ €ÅŸà⁄Øÿß, ⁄©ŸàŸÑŸÖ€åŸÜ €Åÿßÿ¶€å...</td>\n",
              "      <td>ur</td>\n",
              "      <td>Urdu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cefcc82292</td>\n",
              "      <td>Ÿáÿ∞ÿß ŸáŸà ŸÖÿß ÿ™ŸÖ ŸÜÿµÿ≠ŸÜÿß ÿ®Ÿá.</td>\n",
              "      <td>ÿπŸÜÿØŸÖÿß Ÿäÿ™ŸÖ ÿ•ÿÆÿ®ÿßÿ±ŸáŸÖ ÿ®ŸÖÿß Ÿäÿ¨ÿ® ÿπŸÑŸäŸáŸÖ ŸÅÿπŸÑŸá ÿå ŸÅÿ¥ŸÑÿ™ ÿßŸÑ...</td>\n",
              "      <td>ar</td>\n",
              "      <td>Arabic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>e98005252c</td>\n",
              "      <td>et cela est en grande partie d√ª au fait que le...</td>\n",
              "      <td>Les m√®res se droguent.</td>\n",
              "      <td>fr</td>\n",
              "      <td>French</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>58518c10ba</td>\n",
              "      <td>‰∏éÂüéÂ∏ÇÂèäÂÖ∂‰ªñÂÖ¨Ê∞ëÂèäÁ§æÂå∫ÁªÑÁªá‰ª£Ë°®Â∞±IMAÁöÑËâ∫ÊúØÂèëÂ±ïËøõË°åÂØπËØù&amp;amp</td>\n",
              "      <td>IMA‰∏éÂÖ∂‰ªñÁªÑÁªáÂêà‰ΩúÔºåÂõ†‰∏∫ÂÆÉ‰ª¨ÈÉΩ‰æùÈù†ÂÖ±‰∫´ËµÑÈáë„ÄÇ</td>\n",
              "      <td>zh</td>\n",
              "      <td>Chinese</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>c32b0d16df</td>\n",
              "      <td>–û–Ω–∞ –≤—Å–µ –µ—â–µ –±—ã–ª–∞ —Ç–∞–º.</td>\n",
              "      <td>–ú—ã –¥—É–º–∞–ª–∏, —á—Ç–æ –æ–Ω–∞ —É—à–ª–∞, –æ–¥–Ω–∞–∫–æ, –æ–Ω–∞ –æ—Å—Ç–∞–ª–∞—Å—å.</td>\n",
              "      <td>ru</td>\n",
              "      <td>Russian</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  ... language\n",
              "0  c6d58c3f69  ...     Urdu\n",
              "1  cefcc82292  ...   Arabic\n",
              "2  e98005252c  ...   French\n",
              "3  58518c10ba  ...  Chinese\n",
              "4  c32b0d16df  ...  Russian\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_vOtJH7tK-Oa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "d65a7677-117b-4fb2-9c05-44be814fbb93"
      },
      "source": [
        "#peek at a premise/hypothesis pair and their label\n",
        "print(f\"Premise: {train['premise'].values[0]}\")\n",
        "print(f\"Hypothesis: {train['hypothesis'].values[0]}\")\n",
        "print(f\"Label: {train['label'].values[0]}\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Premise: and these comments were considered in formulating the interim rules.\n",
            "Hypothesis: The rules developed in the interim were put together with these comments in mind.\n",
            "Label: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "wKhxVI-TK-Oc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "a7df2b4b-75ae-4a15-b267-b211ef3c089a"
      },
      "source": [
        "#peek at a premise/hypothesis pair and their label\n",
        "print(f\"Premise: {train['premise'].values[1]}\")\n",
        "print(f\"Hypothesis: {train['hypothesis'].values[1]}\")\n",
        "print(f\"Label: {train['label'].values[1]}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Premise: These are issues that we wrestle with in practice groups of law firms, she said. \n",
            "Hypothesis: Practice groups are not permitted to work on these issues.\n",
            "Label: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "arEg6IHvK-Oe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 721
        },
        "outputId": "6b00ba68-febf-4baa-89c2-1f7ac90983fe"
      },
      "source": [
        "#explore the distribution of classes and languages\n",
        "fig, ax = plt.subplots(3, figsize = (15, 10))\n",
        "\n",
        "#for maximum aesthetics\n",
        "palette = sns.cubehelix_palette(8, start=2, rot=0, dark=0, light=.95, reverse=True)\n",
        "\n",
        "graph1 = sns.countplot(train['language'], ax = ax[1], palette = palette)\n",
        "graph2 = sns.countplot(train['label'], ax = ax[0], palette = palette)\n",
        "graph3 = sns.countplot(test['language'], ax = ax[2], palette = palette)\n",
        "\n",
        "#set title\n",
        "graph1.set_title('Distribution of Classes')\n",
        "graph2.set_title('Distribution of Languages')\n",
        "graph3.set_title('Distribution of Languages - Test')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Iyi1swnI9tb",
        "colab_type": "text"
      },
      "source": [
        "# Back-Translation\n",
        "\n",
        "**In computer vision problems, there is a virtual infinitude of techniques you can use to augment your images ranging from simple techniques like randomly flipping images to blending images together with CutMix or MixUp. In natural language processing, it is not as easy to come up with similar augmentation strategies because it is hard to determine which transformations will preserve the meaning of the original words:**\n",
        "\n",
        "![](https://amitness.com/images/semantic-invariance-nlp.png)\n",
        "\n",
        "*Image from [@amitness](https://www.kaggle.com/amitness) on his excellent post on NLP augmentation [here](https://amitness.com/2020/05/data-augmentation-for-nlp/)*   \n",
        "\n",
        "\n",
        "**I initially planned on using synonym swapping, where we randomly replace words with their synonyms, but then I saw [this kernel](https://www.kaggle.com/jpmiller/augmenting-data-with-translations) which is based on [this discussion thread](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/48038) and realized we can do better: we can use 'back-translation':**\n",
        "\n",
        "![](https://amitness.com/images/backtranslation-en-fr.png)\n",
        "\n",
        "*Image from [@amitness](https://www.kaggle.com/amitness) on his excellent post on NLP augmentation [here](https://amitness.com/2020/05/data-augmentation-for-nlp/)*\n",
        "\n",
        "**For now, we will only translate to languages currently present in our dataset, but translating to languages outside of our dataset might give us better performance. Please note that some of these language codes are slightly different within the `googletrans` Python API. See [here](https://py-googletrans.readthedocs.io/en/latest/) for more**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Aq2c-YZvI9tc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "b9d59ebf-ebab-40a3-e827-878cb4e16a98"
      },
      "source": [
        "def translation_aug(sequence, PROB = 1):\n",
        "    languages = ['en', 'fr', 'th', 'tr', 'ur', 'ru', 'bg', 'de', 'ar', 'zh-cn', 'hi',\n",
        "                 'sw', 'vi', 'es', 'el']\n",
        "    \n",
        "    #instantiate translator\n",
        "    translator = Translator()\n",
        "    \n",
        "    #store original language so we can convert back\n",
        "    org_lang = translator.detect(sequence).lang\n",
        "    \n",
        "    #randomly choose language to translate sequence to  \n",
        "    random_lang = np.random.choice([lang for lang in languages if lang is not org_lang])\n",
        "    \n",
        "    if org_lang in languages:\n",
        "        #translate to new language and back to original\n",
        "        translated = translator.translate(sequence, dest = random_lang).text\n",
        "        #translate back to original language\n",
        "        translated_back = translator.translate(translated, dest = org_lang).text\n",
        "    \n",
        "        #apply with certain probability\n",
        "        #this would be used for online augmentation\n",
        "        if np.random.uniform(0, 1) <= PROB:\n",
        "            output_sequence = translated_back\n",
        "        else:\n",
        "            output_sequence = sequence\n",
        "            \n",
        "    #if detected language not in our list of languages, do nothing\n",
        "    else:\n",
        "        output_sequence = sequence\n",
        "    \n",
        "    return output_sequence\n",
        "\n",
        "#check performance\n",
        "for i in range(5):\n",
        "    output = translation_aug('I genuinely have no idea what the output of this sequence of words will be')\n",
        "    print(output)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I really have no idea what this sequence of words will be like\n",
            "I really don't know what the output of this word sequence is\n",
            "I really have no idea what the output of this sequence of words would be\n",
            "I really don‚Äôt know what the results of this sequence of words will be\n",
            "I really have no idea what the result of this sequence of words will be\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8gIcnz0I9td",
        "colab_type": "text"
      },
      "source": [
        "**We need to decide if we want to apply this translation augmentation to the premise/hypothesis at the same time, so each sequence is mapped to the same language and back, or if we want to map them to different languages and back. It's easier to do the latter so I will experiment with it in this commit**\n",
        "\n",
        "**This will also take a little while, so we can use `Dask Bag` to make it faster (more on Dask  [here](https://docs.dask.org/en/latest/bag.html)). Currently, it takes around 30 minutes to translate all the premise/hypothesis pairs from their original langauge, to a random language, and back again when `PROB = 1/2`**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "s8dkuE78I9te",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def translation_aug_parallel(dataset, back = False, undersampled = True):\n",
        "    prem_bag = bag.from_sequence(dataset['premise'].tolist()).map(translation_aug)\n",
        "    hyp_bag =  bag.from_sequence(dataset['hypothesis'].tolist()).map(translation_aug)\n",
        "    \n",
        "    with diagnostics.ProgressBar():\n",
        "        prems = prem_bag.compute()\n",
        "        hyps = hyp_bag.compute()\n",
        "\n",
        "    #pair premises and hypothesis\n",
        "    dataset[['premise', 'hypothesis']] = list(zip(prems, hyps))\n",
        "    \n",
        "    return dataset"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qwctm4oSI9tf",
        "colab_type": "text"
      },
      "source": [
        "**I have already created augmented datasets with the above translation method that can be found [here](https://www.kaggle.com/tuckerarrants/contradictorywatsontranslationaug) and [here](https://www.kaggle.com/tuckerarrants/contradictorywatsontwicetranslatedaug). Let's quickly compare the three separate datasets:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Zh9Ehv_8I9tg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "f67cb193-d97c-4e3f-f915-2387be10ce53"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>premise</th>\n",
              "      <th>hypothesis</th>\n",
              "      <th>lang_abv</th>\n",
              "      <th>language</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5130fd2cb5</td>\n",
              "      <td>and these comments were considered in formulat...</td>\n",
              "      <td>The rules developed in the interim were put to...</td>\n",
              "      <td>en</td>\n",
              "      <td>English</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5b72532a0b</td>\n",
              "      <td>These are issues that we wrestle with in pract...</td>\n",
              "      <td>Practice groups are not permitted to work on t...</td>\n",
              "      <td>en</td>\n",
              "      <td>English</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3931fbe82a</td>\n",
              "      <td>Des petites choses comme celles-l√† font une di...</td>\n",
              "      <td>J'essayais d'accomplir quelque chose.</td>\n",
              "      <td>fr</td>\n",
              "      <td>French</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5622f0c60b</td>\n",
              "      <td>you know they can't really defend themselves l...</td>\n",
              "      <td>They can't defend themselves because of their ...</td>\n",
              "      <td>en</td>\n",
              "      <td>English</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>86aaa48b45</td>\n",
              "      <td>‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡πà‡∏ô‡∏ö‡∏ó‡∏ö‡∏≤‡∏ó‡∏™‡∏°‡∏°‡∏∏‡∏ï‡∏¥‡∏Å‡πá‡πÄ‡∏ä‡πà‡∏ô‡∏Å‡∏±‡∏ô ‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÑ‡∏î‡πâ‡πÅ‡∏™‡∏î...</td>\n",
              "      <td>‡πÄ‡∏î‡πá‡∏Å‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏´‡πá‡∏ô‡πÑ‡∏î‡πâ‡∏ß‡πà‡∏≤‡∏ä‡∏≤‡∏ï‡∏¥‡∏û‡∏±‡∏ô‡∏ò‡∏∏‡πå‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£</td>\n",
              "      <td>th</td>\n",
              "      <td>Thai</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  ... label\n",
              "0  5130fd2cb5  ...     0\n",
              "1  5b72532a0b  ...     2\n",
              "2  3931fbe82a  ...     0\n",
              "3  5622f0c60b  ...     0\n",
              "4  86aaa48b45  ...     1\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "4uhEafr_I9ti",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "5ac425d0-99b4-49ef-98f5-8bba2e0a5355"
      },
      "source": [
        "#offline loading of augmented datasets\n",
        "train_aug = pd.read_csv('translation_aug_train.csv')\n",
        "train_aug.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>premise</th>\n",
              "      <th>hypothesis</th>\n",
              "      <th>lang_abv</th>\n",
              "      <th>language</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5130fd2cb5</td>\n",
              "      <td>and these ideas were considered in the develop...</td>\n",
              "      <td>The rules developed in the interim were taken ...</td>\n",
              "      <td>en</td>\n",
              "      <td>English</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5b72532a0b</td>\n",
              "      <td>These are the challenges we face in practice w...</td>\n",
              "      <td>Practice groups are not permitted to work on t...</td>\n",
              "      <td>en</td>\n",
              "      <td>English</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3931fbe82a</td>\n",
              "      <td>Ces petites choses font une grande diff√©rence ...</td>\n",
              "      <td>J'essaye d'accomplir quelque chose.</td>\n",
              "      <td>fr</td>\n",
              "      <td>French</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5622f0c60b</td>\n",
              "      <td>Do you know that they can't really defend them...</td>\n",
              "      <td>They cannot protect themselves because of age.</td>\n",
              "      <td>en</td>\n",
              "      <td>English</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>86aaa48b45</td>\n",
              "      <td>‡πÄ‡∏•‡πà‡∏ô‡∏ï‡∏≤‡∏°‡∏ö‡∏ó‡∏ö‡∏≤‡∏ó‡∏î‡πâ‡∏ß‡∏¢ ‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏•‡∏∞‡πÄ‡∏•‡πà‡∏ô‡∏ö‡∏ó‡∏ö‡∏≤‡∏ó‡∏´‡∏•‡∏≤...</td>\n",
              "      <td>‡πÄ‡∏î‡πá‡∏Å ‡πÜ ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏´‡πá‡∏ô‡πÑ‡∏î‡πâ‡∏ß‡πà‡∏≤‡∏ä‡∏≤‡∏ï‡∏¥‡∏û‡∏±‡∏ô‡∏ò‡∏∏‡πå‡∏ï‡πà‡∏≤‡∏á‡πÜ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ï...</td>\n",
              "      <td>th</td>\n",
              "      <td>Thai</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  ... label\n",
              "0  5130fd2cb5  ...     0\n",
              "1  5b72532a0b  ...     2\n",
              "2  3931fbe82a  ...     0\n",
              "3  5622f0c60b  ...     0\n",
              "4  86aaa48b45  ...     1\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "b6pqbZq4I9tk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "f79a739c-3fd3-4a1d-9ef4-2f24a1498d17"
      },
      "source": [
        "#offline loading of augmented datasets\n",
        "train_twice_aug = pd.read_csv('twice_translated_aug_train.csv')\n",
        "train_twice_aug.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>premise</th>\n",
              "      <th>hypothesis</th>\n",
              "      <th>lang_abv</th>\n",
              "      <th>language</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5130fd2cb5</td>\n",
              "      <td>and these ideas were taken into consideration ...</td>\n",
              "      <td>Interim rules developed in conjunction with th...</td>\n",
              "      <td>en</td>\n",
              "      <td>English</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5b72532a0b</td>\n",
              "      <td>These are the challenges we face in practice w...</td>\n",
              "      <td>Practice groups are not allowed to deal with t...</td>\n",
              "      <td>en</td>\n",
              "      <td>English</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3931fbe82a</td>\n",
              "      <td>Ces petites choses font une grande diff√©rence ...</td>\n",
              "      <td>J'essaye d'accomplir quelque chose.</td>\n",
              "      <td>fr</td>\n",
              "      <td>French</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5622f0c60b</td>\n",
              "      <td>Do you know that they can't really defend them...</td>\n",
              "      <td>They cannot protect themselves because of age.</td>\n",
              "      <td>en</td>\n",
              "      <td>English</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>86aaa48b45</td>\n",
              "      <td>‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡πà‡∏ô‡∏ö‡∏ó‡∏ö‡∏≤‡∏ó‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏¢‡∏±‡∏á‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡πÄ‡∏Å‡∏¥‡∏î‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡πÉ‡∏ô‡∏Å‡∏≤...</td>\n",
              "      <td>‡πÄ‡∏î‡πá‡∏Å ‡πÜ ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏´‡πá‡∏ô‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ó‡∏≤‡∏á‡∏ä‡∏≤‡∏ï‡∏¥‡∏û‡∏±‡∏ô‡∏ò‡∏∏‡πå‡∏ó‡∏µ‡πà‡πÅ‡∏ï‡∏Å‡∏ï...</td>\n",
              "      <td>th</td>\n",
              "      <td>Thai</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  ... label\n",
              "0  5130fd2cb5  ...     0\n",
              "1  5b72532a0b  ...     2\n",
              "2  3931fbe82a  ...     0\n",
              "3  5622f0c60b  ...     0\n",
              "4  86aaa48b45  ...     1\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewZJ-Xm0I9tn",
        "colab_type": "text"
      },
      "source": [
        "**Wonderful! Now you could take this dataset and apply the same procedure to generate an ever more diverse set of augmentations, or you could increase the complexity of the translation by chaining together multiple languages, i.e.**\n",
        "\n",
        "> English -> French -> Russian -> .... -> English\n",
        "\n",
        "**I encourage you to play around with this yourself to see what gives you the best performance**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AS17fjOI9tn",
        "colab_type": "text"
      },
      "source": [
        "# External Datasets\n",
        "\n",
        "**Now, since this is not a strict competition, we can use external datasets. HuggingFace transformers makes it incredibly easy to import hundreds of thousands of NLI labeled data in minutes. If we choose to train our model with these samples, it will be much more powerful. In a real project, you would definitely just sprinkle in some of these examples until you reach your desired balance of performance/training time, so in this notebook, we will include it to see just how accurate XLM-R can get when trained on a large amount of NLI data**\n",
        "\n",
        "### MNLI Corpus\n",
        "\n",
        "**Here we will import additional NLI datasets, The first we can import is the [Multi-Genre NLI Corpus](https://cims.nyu.edu/~sbowman/multinli/) (MNLI). It is a crowd sourced collection of 433k sentence pairs annotated with the same labels as our dataset. We can easily import it with the new HuggingFace library `nlp`, more about this [here](https://huggingface.co/datasets/multi_nli)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXa_YFzTPCaO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "85bd7062-24bd-46c3-9795-8f37d2b39cd0"
      },
      "source": [
        "!pip install numpy==1.19.1"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy==1.19.1 in /usr/local/lib/python3.6/dist-packages (1.19.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "X40L--Y_I9tn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install --quiet nlp"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "UOzlHIIBI9tp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load mnli dataset\n",
        "import nlp\n",
        "mnli = nlp.load_dataset(\"multi_nli\")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8g5P1YKsI9tr",
        "colab_type": "text"
      },
      "source": [
        "**Let's explore this external dataset to make sure it aligns with our needs:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "CmsB8kq9I9tr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d5d7a002-f12d-40cd-db57-56bc3b4872ce"
      },
      "source": [
        "#check number of samples in train\n",
        "mnli['train'].num_rows"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "392702"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "PNZQWFRyI9tt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "30f47572-b13a-4460-c8e5-433a9b85f175"
      },
      "source": [
        "#view sample\n",
        "mnli['train'][1]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'hypothesis': 'You lose the things to the following level if the people recall.',\n",
              " 'label': 0,\n",
              " 'premise': 'you know during the season and i guess at at your level uh you lose them to the next level if if they decide to recall the the parent team the Braves decide to call to recall a guy from triple A then a double A guy goes up to replace him and a single A guy goes up to replace him'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUdQ-P7eI9tv",
        "colab_type": "text"
      },
      "source": [
        "### Adding External NLI Datasets\n",
        "\n",
        "**Here we will add the external NLI datasets to our training dataset:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_wDlZK3vI9tv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "6728e658-54a2-4404-e2cd-ed1519c04f32"
      },
      "source": [
        "#convert to a dataframe and view\n",
        "mnli_df = pd.DataFrame(mnli['train'])\n",
        "mnli_df = mnli_df[['premise', 'hypothesis', 'label']]\n",
        "mnli_df.head(9)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>premise</th>\n",
              "      <th>hypothesis</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Conceptually cream skimming has two basic dime...</td>\n",
              "      <td>Product and geography are what make cream skim...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>you know during the season and i guess at at y...</td>\n",
              "      <td>You lose the things to the following level if ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>One of our number will carry out your instruct...</td>\n",
              "      <td>A member of my team will execute your orders w...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How do you know? All this is their information...</td>\n",
              "      <td>This information belongs to them.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>yeah i tell you what though if you go price so...</td>\n",
              "      <td>The tennis shoes have a range of prices.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>my walkman broke so i'm upset now i just have ...</td>\n",
              "      <td>I'm upset that my walkman broke and now I have...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>But a few Christian mosaics survive above the ...</td>\n",
              "      <td>Most of the Christian mosaics were destroyed b...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>(Read  for Slate 's take on Jackson's findings.)</td>\n",
              "      <td>Slate had an opinion on Jackson's findings.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Gays and lesbians.</td>\n",
              "      <td>Heterosexuals.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             premise  ... label\n",
              "0  Conceptually cream skimming has two basic dime...  ...     1\n",
              "1  you know during the season and i guess at at y...  ...     0\n",
              "2  One of our number will carry out your instruct...  ...     0\n",
              "3  How do you know? All this is their information...  ...     0\n",
              "4  yeah i tell you what though if you go price so...  ...     1\n",
              "5  my walkman broke so i'm upset now i just have ...  ...     0\n",
              "6  But a few Christian mosaics survive above the ...  ...     1\n",
              "7   (Read  for Slate 's take on Jackson's findings.)  ...     0\n",
              "8                                 Gays and lesbians.  ...     2\n",
              "\n",
              "[9 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ANcyLBBiI9tx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "43211f4c-4073-431f-eb78-0159a48eeb70"
      },
      "source": [
        "#add to train\n",
        "train = train[['premise', 'hypothesis', 'label']]\n",
        "\n",
        "if ADD_MNLI:\n",
        "    #add all of mnli\n",
        "    #train = train.append(mnli_df)\n",
        "    \n",
        "    #add only every other sample from MLNI dataset\n",
        "    #train = train.append(mnli_df[mnli_df.index % 2 == 0])\n",
        "    \n",
        "    #add only every third sample from MLNI dataset\n",
        "    train = train.append(mnli_df[mnli_df.index % 3 == 0])\n",
        "    \n",
        "    #add only every 10th sample from MLNI dataset\n",
        "    #train = train.append(mnli_df[mnli_df.index % 10 == 0])\n",
        "    \n",
        "    #sanity check\n",
        "    print('Training size after adding external MNLI dataset:', train.shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training size after adding external MNLI dataset: (143021, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YP4PsHc8I9ty",
        "colab_type": "text"
      },
      "source": [
        "### Translating MNLI\n",
        "\n",
        "**We can use `nlp` to load another dataset known as [XLNI](https://huggingface.co/datasets/xnli), but this is just a subset of MNLI that has been translated into 14 different low resource languages (undersampled), so we can produce something similar ourselves. First, let's see how to load it from `nlp`:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "FCkr_SJ3I9tz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#offline loading of XLNI\n",
        "xnli = nlp.load_dataset(\"xnli\")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "hnFDFvcxI9t0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0da9bef9-37ae-4325-e323-7bfab00e8fd5"
      },
      "source": [
        "#check number of samples in train\n",
        "xnli['validation'].num_rows"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2490"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "gxZ1ZCyuI9t2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 834
        },
        "outputId": "d18ccf9c-1e62-4f92-e6ab-105faed09247"
      },
      "source": [
        "#view sample\n",
        "xnli['validation'][1]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'hypothesis': {'language': ['ar',\n",
              "   'bg',\n",
              "   'de',\n",
              "   'el',\n",
              "   'en',\n",
              "   'es',\n",
              "   'fr',\n",
              "   'hi',\n",
              "   'ru',\n",
              "   'sw',\n",
              "   'th',\n",
              "   'tr',\n",
              "   'ur',\n",
              "   'vi',\n",
              "   'zh'],\n",
              "  'translation': ['ŸÑŸÖ ŸäŸÜÿ∑ŸÇ ÿ®ÿ®ŸÜÿ™ ÿ¥ŸÅÿ©.',\n",
              "   '–¢–æ–π –Ω–µ –∫–∞–∑–∞ –Ω–∏—Ç–æ –¥—É–º–∞.',\n",
              "   'Er sagte kein Wort.',\n",
              "   'ŒîŒµŒΩ ŒµŒØœÄŒµ ŒøœçœÑŒµ ŒªŒ≠ŒæŒ∑.',\n",
              "   \"He didn't say a word.\",\n",
              "   '√âl no dijo una palabra.',\n",
              "   \"Il n'a pas dit un mot.\",\n",
              "   '‡§â‡§∏‡§®‡•á ‡§è‡§ï ‡§∂‡§¨‡•ç‡§¶ ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§π‡§æ‡•§',\n",
              "   '–û–Ω –Ω–µ –ø—Ä–æ–∏–∑–Ω–µ—Å –Ω–∏ —Å–ª–æ–≤–∞.',\n",
              "   'Hakusema chochote.',\n",
              "   '‡πÄ‡∏Ç‡∏≤‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏û‡∏π‡∏î‡∏™‡∏±‡∏Å‡∏Ñ‡∏≥',\n",
              "   'Bir kelime s√∂ylemedi.',\n",
              "   'Ÿà⁄∫ ÿß €å⁄© ŸÑŸÅÿ≤ ŸÜ⁄æ€å ÿ®ŸàŸÑÿß',\n",
              "   'Anh kh√¥ng n√≥i m·ªôt l·ªùi n√†o.',\n",
              "   '‰ªñÊ≤°ËØ¥‰∏ÄÂè•ËØù„ÄÇ']},\n",
              " 'label': 2,\n",
              " 'premise': {'ar': 'ŸàŸÇÿßŸÑÿå ŸÖÿßŸÖÿßÿå ŸÑŸÇÿØ ÿπÿØÿ™ ŸÑŸÑŸÖŸÜÿ≤ŸÑ.',\n",
              "  'bg': '–ò —Ç–æ–π –∫–∞–∑–∞: –ú–∞–º–æ, —É –¥–æ–º–∞ —Å—ä–º.',\n",
              "  'de': 'und er hat gesagt, Mama ich bin daheim.',\n",
              "  'el': 'ŒöŒ±Œπ ŒµŒØœÄŒµ, ŒúŒ±ŒºŒ¨, Œ≠œÜœÑŒ±œÉŒ± œÉœÑŒø œÉœÄŒØœÑŒπ.',\n",
              "  'en': \"And he said, Mama, I'm home.\",\n",
              "  'es': 'Y √©l dijo: Mam√°, estoy en casa.',\n",
              "  'fr': 'Et il a dit, maman, je suis √† la maison.',\n",
              "  'hi': '‡§î‡§∞ ‡§â‡§∏‡§®‡•á ‡§ï‡§π‡§æ, ‡§Æ‡§æ‡§Å, ‡§Æ‡•à‡§Ç ‡§ò‡§∞ ‡§Ü‡§Ø‡§æ ‡§π‡•Ç‡§Ç‡•§',\n",
              "  'ru': '–ò –æ–Ω —Å–∫–∞–∑–∞–ª: –ú–∞–º–∞, —è –¥–æ–º–∞.',\n",
              "  'sw': 'Naye akasema, Mama, niko nyumbani.',\n",
              "  'th': '‡πÅ‡∏•‡∏∞‡πÄ‡∏Ç‡∏≤‡∏û‡∏π‡∏î‡∏ß‡πà‡∏≤, ‡∏°‡πà‡∏≤‡∏°‡πä‡∏≤ ‡∏ú‡∏°‡∏≠‡∏¢‡∏π‡πà‡∏ö‡πâ‡∏≤‡∏ô',\n",
              "  'tr': 'Ve Anne, evdeyim dedi.',\n",
              "  'ur': 'ÿßŸàÿ± ÿßÿ≥ ŸÜ€í ⁄©€Åÿß ÿßŸÖŸë€åÿå ŸÖ€å⁄∫ ⁄Ø⁄æÿ± ÿ¢⁄Ø€åÿß €ÅŸà⁄∫€î',\n",
              "  'vi': 'V√† anh ·∫•y n√≥i, M·∫π, con ƒë√£ v·ªÅ nh√†.',\n",
              "  'zh': '‰ªñËØ¥ÔºåÂ¶àÂ¶àÔºåÊàëÂõûÊù•‰∫Ü„ÄÇ'}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lC70LwpMI9t4",
        "colab_type": "text"
      },
      "source": [
        "**We can manually create an XNLI dataset if we translate a small set of premise/hypothesis pairs from MNLI to under sampled languages in our dataset. This gives us the ability to oversample certain languages, countering against language imbalances in our training dataset. The below code randomly translates 1500 MNLI samples to Urdu and another 1500 samples to Swahili**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "IhRoIttJI9t4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "119d84d3-e356-4314-aadc-3727a30ef1f5"
      },
      "source": [
        "#instantiate translator\n",
        "translator = Translator()\n",
        "    \n",
        "#select small set of MNLI to translate\n",
        "mnli_sample = mnli_df[mnli_df.index % 100 == 0]\n",
        "\n",
        "#shuffle sample\n",
        "mnli_sample = shuffle(mnli_sample)\n",
        "\n",
        "if ADD_XMNLI:\n",
        "    print('Training size before adding external XMNLI dataset:', train.shape)\n",
        "    #translate half to Urdu\n",
        "    print('Translating to Urdu...'); print('')\n",
        "    mnli_sample[:len(mnli_sample)//2]['premise'].apply(lambda prem: translator.translate(prem, dest = 'ur').text)\n",
        "    mnli_sample[:len(mnli_sample)//2]['hypothesis'].apply(lambda prem: translator.translate(prem, dest = 'ur').text)\n",
        "\n",
        "    #translate half to Swahili\n",
        "    print('Translating to Swahili...');print('')\n",
        "    mnli_sample[len(mnli_sample)//2:]['premise'].apply(lambda prem: translator.translate(prem, dest = 'sw').text)\n",
        "    mnli_sample[len(mnli_sample)//2:]['hypothesis'].apply(lambda prem: translator.translate(prem, dest = 'sw').text)\n",
        "    \n",
        "    #add to training dataset\n",
        "    train = train.append(mnli_sample)\n",
        "    \n",
        "    #sanity check\n",
        "    print('Training size after adding external XMNLI dataset:', train.shape)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training size before adding external XMNLI dataset: (143021, 3)\n",
            "Translating to Urdu...\n",
            "\n",
            "Translating to Swahili...\n",
            "\n",
            "Training size after adding external XMNLI dataset: (146949, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCYQZr0AK-Og",
        "colab_type": "text"
      },
      "source": [
        "# Configure TPU\n",
        "\n",
        "**Now we have to make some TPU-training specific changes. First, we must connect to and initialize our TPU:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "5baypFOGK-Oh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 854
        },
        "outputId": "04136f72-2cbb-43d9-c84b-e726fcd17dd3"
      },
      "source": [
        "if DEVICE == \"TPU\":\n",
        "    print(\"connecting to TPU...\")\n",
        "    try:\n",
        "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "        print('Running on TPU ', tpu.master())\n",
        "    except ValueError:\n",
        "        print(\"Could not connect to TPU\")\n",
        "        tpu = None\n",
        "\n",
        "    if tpu:\n",
        "        try:\n",
        "            print(\"initializing  TPU ...\")\n",
        "            tf.config.experimental_connect_to_cluster(tpu)\n",
        "            tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "            strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "            print(\"TPU initialized\")\n",
        "        except _:\n",
        "            print(\"failed to initialize TPU\")\n",
        "    else:\n",
        "        DEVICE = \"GPU\"\n",
        "\n",
        "if DEVICE != \"TPU\":\n",
        "    print(\"Using default strategy for CPU and single GPU\")\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "\n",
        "if DEVICE == \"GPU\":\n",
        "    print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "    \n",
        "\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "REPLICAS = strategy.num_replicas_in_sync\n",
        "#REPLICAS = 8\n",
        "print(f'REPLICAS: {REPLICAS}')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "connecting to TPU...\n",
            "Running on TPU  grpc://10.100.79.50:8470\n",
            "initializing  TPU ...\n",
            "INFO:tensorflow:Initializing the TPU system: grpc://10.100.79.50:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.100.79.50:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TPU initialized\n",
            "REPLICAS: 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "yI04p1euK-Oi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#choose batch size - will depend on cores of our device\n",
        "BATCH_SIZE = 32 * REPLICAS"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5nXqI4AK-Oo",
        "colab_type": "text"
      },
      "source": [
        "# Getting Datasets\n",
        "\n",
        "**HuggingFace Transformers makes it unbelievable easy to use transformers. In fact, you don't even need to specify the transformer or tokenizer: its architecture can be guessed from the name or path of the pretrained model you specify in the `from_pretrained` method. To read more about AutoModels/Tokenizers, see [this](https://huggingface.co/transformers/model_doc/auto.html)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "gqeX9fczK-Ok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get HuggingFace transformers\n",
        "!pip install --quiet transformers\n",
        "\n",
        "#import model and Tokenizer\n",
        "from transformers import TFAutoModel, AutoTokenizer\n",
        "\n",
        "#get paths to TensorFlow XLM-RoBERTa base and large models\n",
        "roberta_base = \"jplu/tf-xlm-roberta-base\"\n",
        "roberta_large = 'jplu/tf-xlm-roberta-large'"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGDUq3o-I9uA",
        "colab_type": "text"
      },
      "source": [
        "## Augmented Datasets\n",
        "\n",
        "**We can start by creating a simple train/validation split here and then converting them to `tf.data.Dataset` format which is the format we need to put our datasets into before we send them to the TPUs. For more about buidling data pipelines in TensorFlow, see [here](https://www.tensorflow.org/guide/data):**\n",
        "\n",
        "**Now, we do not want any samples in our validation set used to create the augmented dataset, or we will overfit our validation data. So you can either split your data into train and validation first and then augment only on train, or you can import the offline dataset and manually remove the validation indices from it and add that to the original training data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Ko91R5R8I9uA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ac37bc6e-788b-4ca1-f385-7f1e65e1dec4"
      },
      "source": [
        "#get train, val splits\n",
        "train, val, train_labels, val_labels = train_test_split(train, train['label'],\n",
        "                                                        test_size = 0.2,\n",
        "                                                        random_state = SEED)\n",
        "\n",
        "#check size before augmenting\n",
        "print(f'Training size before translation augmentation: {len(train)}')\n",
        "\n",
        "if GEN_AUG:\n",
        "    #now we generate augmented data\n",
        "    train_aug = train.copy().pipe(translation_aug_parallel)\n",
        "\n",
        "if ADD_AUG:\n",
        "    #remove validation indexs samples from our augmented dataset\n",
        "    train_aug = train_aug.drop(val.index)\n",
        "    train_twice_aug = train_twice_aug.drop(val.index)\n",
        "\n",
        "    #and shuffle\n",
        "    train_aug = shuffle(train_aug)\n",
        "    train_twice_aug = shuffle(train_twice_aug)\n",
        "\n",
        "    #add only twice augmented dataset to existing training dataset\n",
        "    train = train.append(train_twice_aug)\n",
        "    train_labels = train_labels.append(train_twice_aug['label'])\n",
        "\n",
        "    #add both external datasets to existing training dataset\n",
        "    #train = train.append([train_aug, train_twice_aug])\n",
        "    #train_labels = train_labels.append([train_aug['label'], train_twice_aug['label']])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training size before translation augmentation: 117559\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "aBwflbRnI9uC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b885e850-15fb-4825-f29a-1350496913f6"
      },
      "source": [
        "#check size after augmenting\n",
        "print(f'Training size after translation augmentation: {len(train)}')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training size after translation augmentation: 117559\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "i470uUitK-Om",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "outputId": "5a6554d3-8d1b-40a3-ab14-566dfb07730c"
      },
      "source": [
        "#create tokenzer object\n",
        "TOKENIZER = AutoTokenizer.from_pretrained(roberta_large)\n",
        "\n",
        "#define inputs to give our tokenizer (and training labels)\n",
        "train_text = train[['premise', 'hypothesis']].values.tolist()\n",
        "val_text = val[['premise', 'hypothesis']].values.tolist()\n",
        "test_text = test[['premise', 'hypothesis']].values.tolist()\n",
        "\n",
        "#tokenize our text here\n",
        "#will functionize these later\n",
        "print('Encoding train...')\n",
        "train_enc = TOKENIZER.batch_encode_plus(\n",
        "    train_text,\n",
        "    pad_to_max_length = True,\n",
        "    max_length = MAX_LEN\n",
        ")\n",
        "print('')\n",
        "\n",
        "print('Encoding validation...')\n",
        "val_enc = TOKENIZER.batch_encode_plus(\n",
        "    val_text,\n",
        "    pad_to_max_length = True,\n",
        "    max_length = MAX_LEN\n",
        ")\n",
        "print('')\n",
        "\n",
        "print('Encoding test...')\n",
        "test_enc = TOKENIZER.batch_encode_plus(\n",
        "    test_text,\n",
        "    pad_to_max_length = True,\n",
        "    max_length = MAX_LEN\n",
        ")\n",
        "print('')\n",
        "print('Done')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:transformers.tokenization_utils_base:Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Encoding train...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:transformers.tokenization_utils_base:Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Encoding validation...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:transformers.tokenization_utils_base:Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Encoding test...\n",
            "\n",
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-LCYg07JK-Op",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "e1cc21f2-0de1-4a98-93b0-4c57c1b58d05"
      },
      "source": [
        "#convert train dataset to tf.data.Dataset format\n",
        "print('Converting train dataset to TPU format...')\n",
        "train_ds = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((train_enc['input_ids'], train_labels))\n",
        "    .repeat()\n",
        "    .shuffle(2048)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .prefetch(AUTO)\n",
        ")\n",
        "print('')\n",
        "\n",
        "#convert validation dataset to tf.data.Dataset format\n",
        "print('Converting validation dataset to TPU format...')\n",
        "val_ds = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((val_enc['input_ids'], val_labels))\n",
        "    .batch(BATCH_SIZE)\n",
        "    .prefetch(AUTO)\n",
        ")\n",
        "print('')\n",
        "\n",
        "#convert test dataset to tf.data.Dataset format\n",
        "print('Converting test dataset to TPU format...')\n",
        "test_ds = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices(test_enc['input_ids'])\n",
        "    .batch(BATCH_SIZE)\n",
        ")\n",
        "print('')\n",
        "print('Done')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Converting train dataset to TPU format...\n",
            "\n",
            "Converting validation dataset to TPU format...\n",
            "\n",
            "Converting test dataset to TPU format...\n",
            "\n",
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uAHlCN6K-Os",
        "colab_type": "text"
      },
      "source": [
        "# Learning Rate Schedule\n",
        "\n",
        "**It is generally a good idea to use a learning rate scheduler when transfer learning. Our pretrained model already knows quite a bit, so we want to start the learning rate at 0: if we start with a high learning rate, there is a chance we 'erase' the weights that the model already had, defeating the purpose of transfer learning. We then slowly increase the learning rate as the model adapts to the new data:** \n",
        "\n",
        "**Note that I am still figuring out the best learning rate schedule as the current one does not seem to provide much increase in score/smoother training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "mruu9foJK-Os",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "2d10f77f-56ff-41d9-9917-723f176910c7"
      },
      "source": [
        "#define learning rate parameters\n",
        "LR_START = 1e-6\n",
        "LR_MAX = 1e-6 * REPLICAS\n",
        "LR_MIN = 1e-6\n",
        "LR_RAMPUP_EPOCHS = 3\n",
        "LR_SUSTAIN_EPOCHS = 0\n",
        "LR_DECAY = .8\n",
        "\n",
        "#stepwise schedule\n",
        "def lrfn_step(epoch):\n",
        "    if epoch < LR_RAMPUP_EPOCHS:\n",
        "        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n",
        "    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n",
        "        lr = LR_MAX\n",
        "    else:\n",
        "        lr = LR_MAX * LR_DECAY**((epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS)//2)\n",
        "    return lr\n",
        "\n",
        "\n",
        "#smoothish schedule\n",
        "def lrfn_smooth(epoch):\n",
        "    if epoch < LR_RAMPUP_EPOCHS:\n",
        "        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n",
        "    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n",
        "        lr = LR_MAX\n",
        "    else:\n",
        "        lr = (LR_MAX - LR_MIN) * LR_DECAY**(epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) + LR_MIN\n",
        "    return lr\n",
        "    \n",
        "lr_callback_step = tf.keras.callbacks.LearningRateScheduler(lrfn_step, verbose = True)\n",
        "lr_callback_smooth = tf.keras.callbacks.LearningRateScheduler(lrfn_smooth, verbose = True)\n",
        "\n",
        "#visualize learning rate schedule\n",
        "rng = [i for i in range(EPOCHS)]\n",
        "y1 = [lrfn_step(x) for x in rng]\n",
        "y2 = [lrfn_smooth(x) for x in rng]\n",
        "fix, ax = plt.subplots(1,2)\n",
        "ax[0].plot(rng, y1)\n",
        "ax[1].plot(rng, y2)\n",
        "plt.tight_layout()\n",
        "print(\"Learning rate schedule for step schedule: {:.3g} to {:.3g} to {:.3g}\".format(y1[0], max(y1), y1[-1]))\n",
        "print(\"Learning rate schedule for smooth schedule: {:.3g} to {:.3g} to {:.3g}\".format(y2[0], max(y2), y2[-1]))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate schedule for step schedule: 1e-06 to 8e-06 to 4.1e-06\n",
            "Learning rate schedule for smooth schedule: 1e-06 to 8e-06 to 2.84e-06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aax9hzclK-Ou",
        "colab_type": "text"
      },
      "source": [
        "# Model Training\n",
        "\n",
        "**We can use the `mish` activation here which is a non-monotonic activation function that tends to work better than `relu`. You can read more about it [here](https://arxiv.org/abs/1908.08681#:~:text=Mish%3A%20A%20Self%20Regularized%20Non%2DMonotonic%20Neural%20Activation%20Function,-Diganta%20Misra&text=In%20this%20work%2C%20a%20novel,deep%20networks%20across%20challenging%20datasets). Sadly, it is not a predefined activation function in `tf.keras` so we need to construct it ourselves, which is easy to do**\n",
        "\n",
        "**Here is a quick graphic that shows the differences between the most popular activation functions:**\n",
        "\n",
        "![](https://raw.githubusercontent.com/krutikabapat/krutikabapat.github.io/master/assets/activation.png)\n",
        "\n",
        "*Image taken from [here](https://krutikabapat.github.io/Swish-Vs-Mish-Latest-Activation-Functions/)*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "JBL0oVMsI9uJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.math import softplus, tanh\n",
        "from tensorflow.keras.utils import get_custom_objects\n",
        "from tensorflow.keras.layers import Dense, Input, Activation, Dropout\n",
        "\n",
        "# softplus - log(exp(x)+1)\n",
        "def mish(x):\n",
        "    return x*tanh(softplus(x))\n",
        "\n",
        "#create misch activation to use in tf.keras\n",
        "get_custom_objects()[\"mish\"] = Activation(mish)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "pbO97U7qK-Ou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#helper function to create our model\n",
        "def build_model(transformer_layer, learning_rate = LR_RATE):\n",
        "    #must use this to send to TPU cores\n",
        "    with strategy.scope():\n",
        "        #define input(s)\n",
        "        input_ids = tf.keras.Input(shape = (MAX_LEN,), dtype = tf.int32)\n",
        "        \n",
        "        #insert roberta layer\n",
        "        roberta = TFAutoModel.from_pretrained(transformer_layer)\n",
        "        roberta = roberta(input_ids)[0]\n",
        "        \n",
        "        #only need <s> token here, so we extract it now\n",
        "        out = roberta[:, 0, :]\n",
        "        \n",
        "        #add optional Dense layer with dropout\n",
        "        #out = tf.keras.layers.Dropout(.2)(out)\n",
        "        \n",
        "        #two layers with mish activation\n",
        "        #out = tf.keras.layers.Dense(MAX_LEN // 2, activation='mish')(out)\n",
        "        #out = tf.keras.layers.Dense(MAX_LEN // 4, activation='mish')(out)\n",
        "        \n",
        "        #two layers with relu activation\n",
        "        #out = tf.keras.layers.Dense(32, activation = 'relu')(out)\n",
        "        #out = tf.keras.layers.Dense(16, activation = 'relu')(out)\n",
        "        \n",
        "        #add our softmax layer\n",
        "        out = tf.keras.layers.Dense(3, activation = 'softmax')(out)\n",
        "        \n",
        "        #assemble model and compile\n",
        "        model = tf.keras.Model(inputs = input_ids, outputs = out)\n",
        "        model.compile(\n",
        "                        optimizer = tf.keras.optimizers.Adam(lr = LR_RATE), \n",
        "                        loss = 'sparse_categorical_crossentropy', \n",
        "                        metrics = ['accuracy'])\n",
        "        \n",
        "    return model  "
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWb6BlCUI9uM",
        "colab_type": "text"
      },
      "source": [
        "**Some people don't believe in saving the best model and loading it after training. For one, it takes up extra space, especially if your model has hundreds of millions of parameters. In fact, you can only save 3 copies of RoBERTa-large to Kaggle memory before you run out of space**\n",
        "\n",
        "**Secondly, your training should be stable, so setting your training to a fixed number of epochs should produce similar results as using a `val_loss` monitor. If you are worried that training your model for one or two more epochs will completely throw your weights off, then you haven't found good weights for your model (for smaller models where you can easily regularize your model to train for longer periods of time). That being said, RoBERTa is a large model that can quickly overfit a dataset in a single epoch, so we will use a `val_loss` checkpoint callback:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "y-teFNvHI9uM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 996
        },
        "outputId": "8e8394ab-ca84-43b2-e6ce-f8bb2e8ea89e"
      },
      "source": [
        "#choose to see training\n",
        "#0 for nothing, 1 for progress bar, 2 for each epoch\n",
        "VERBOSE = 2\n",
        "\n",
        "#to clear the TPU memory\n",
        "print('---' *20)\n",
        "print(f\"Getting model...\")\n",
        "if DEVICE == 'TPU':\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    \n",
        "#get steps per epoch values\n",
        "STEPS_PER_EPOCH = len(train) // BATCH_SIZE\n",
        "\n",
        "#make callback to save best model from training\n",
        "save_callback = tf.keras.callbacks.ModelCheckpoint(f\"best_model.h5\", monitor = 'val_loss', verbose = 0,\n",
        "                        save_best_only = True, save_weights_only = True, mode = 'min')\n",
        "\n",
        "#build and make save callback\n",
        "RoBERTa = build_model(roberta_base)\n",
        "print(f\"Training with batch size {BATCH_SIZE}\")\n",
        "\n",
        "#and train\n",
        "history = RoBERTa.fit(train_ds, steps_per_epoch = STEPS_PER_EPOCH,\n",
        "                      #validation_split = .2, \n",
        "                      validation_data = val_ds,\n",
        "                      epochs = EPOCHS, verbose = VERBOSE,\n",
        "                      callbacks = [save_callback],\n",
        "                      #callbacks = [save_callback, lr_callback_smooth]\n",
        "                      )"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------------------------------------\n",
            "Getting model...\n",
            "WARNING:tensorflow:TPU system grpc://10.100.79.50:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.100.79.50:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.100.79.50:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.100.79.50:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:transformers.modeling_tf_utils:Some weights of the model checkpoint at jplu/tf-xlm-roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "WARNING:transformers.modeling_tf_utils:All the weights of TFRobertaModel were initialized from the model checkpoint at jplu/tf-xlm-roberta-base.\n",
            "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training with batch size 256\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Iterator.get_next_as_optional()` instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Iterator.get_next_as_optional()` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0082s vs `on_train_batch_end` time: 0.2130s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0082s vs `on_train_batch_end` time: 0.2130s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0037s vs `on_test_batch_end` time: 0.0518s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0037s vs `on_test_batch_end` time: 0.0518s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "459/459 - 169s - loss: 1.1003 - accuracy: 0.4362 - val_loss: 0.8456 - val_accuracy: 0.6317\n",
            "Epoch 2/10\n",
            "459/459 - 116s - loss: 0.7346 - accuracy: 0.6856 - val_loss: 0.6124 - val_accuracy: 0.7509\n",
            "Epoch 3/10\n",
            "459/459 - 117s - loss: 0.5993 - accuracy: 0.7543 - val_loss: 0.5726 - val_accuracy: 0.7737\n",
            "Epoch 4/10\n",
            "459/459 - 117s - loss: 0.5331 - accuracy: 0.7860 - val_loss: 0.5448 - val_accuracy: 0.7870\n",
            "Epoch 5/10\n",
            "459/459 - 109s - loss: 0.4842 - accuracy: 0.8082 - val_loss: 0.5479 - val_accuracy: 0.7864\n",
            "Epoch 6/10\n",
            "459/459 - 117s - loss: 0.4431 - accuracy: 0.8257 - val_loss: 0.5423 - val_accuracy: 0.7944\n",
            "Epoch 7/10\n",
            "459/459 - 109s - loss: 0.4034 - accuracy: 0.8434 - val_loss: 0.5602 - val_accuracy: 0.7969\n",
            "Epoch 8/10\n",
            "459/459 - 109s - loss: 0.3677 - accuracy: 0.8576 - val_loss: 0.5672 - val_accuracy: 0.8008\n",
            "Epoch 9/10\n",
            "459/459 - 109s - loss: 0.3332 - accuracy: 0.8733 - val_loss: 0.6004 - val_accuracy: 0.8014\n",
            "Epoch 10/10\n",
            "459/459 - 109s - loss: 0.2995 - accuracy: 0.8875 - val_loss: 0.6264 - val_accuracy: 0.7980\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXkVdrpTI9uP",
        "colab_type": "text"
      },
      "source": [
        "**Once the model's weights have been saved to the disk, we can easily load them into an untrained model. This means we only need to train once and then we can store the weights in another notebook with other model weights to easily compare the performance of different models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "0XtLcmG1I9uP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "bcb154d7-b54d-4b70-b916-106f2d3188ed"
      },
      "source": [
        "#load best model\n",
        "print('Loading best model...')\n",
        "RoBERTa.load_weights(f\"best_model.h5\")\n",
        "print('Best model loaded')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading best model...\n",
            "Best model loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yHKq8prI9uQ",
        "colab_type": "text"
      },
      "source": [
        "# Test Time Augmentation\n",
        "\n",
        "**Here we will experiment with test time augmentation by predicting on our 3 separate test datasets and then averaging the results. This is standard practice in computer vision so I want to test it in NLP to see how it performs:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "MkaLRHwmI9uR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "d96092a2-49b7-46ef-9069-f5ac118701aa"
      },
      "source": [
        "#get external augmented test sets\n",
        "test_aug = pd.read_csv('translation_aug_test.csv')\n",
        "test_twice_aug = pd.read_csv('twice_translated_aug_test.csv')\n",
        "\n",
        "#compare different datasets\n",
        "print(test.shape)\n",
        "test.head()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5195, 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>premise</th>\n",
              "      <th>hypothesis</th>\n",
              "      <th>lang_abv</th>\n",
              "      <th>language</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>c6d58c3f69</td>\n",
              "      <td>ÿ®⁄©ÿ≥ÿå ⁄©€åÿ≥€åÿå ÿ±ÿß€Å€åŸÑÿå €åÿ≥ÿπ€åÿß€Åÿå ⁄©€åŸÑ€åÿå ⁄©€åŸÑ€åÿå ÿßŸàÿ± ⁄©ŸàŸÑŸÖ...</td>\n",
              "      <td>⁄©€åÿ≥€å ⁄©€í ŸÑÿ¶€í ⁄©Ÿàÿ¶€å €åÿßÿØ⁄Øÿßÿ± ŸÜ€Å€å⁄∫ €ÅŸà⁄Øÿß, ⁄©ŸàŸÑŸÖ€åŸÜ €Åÿßÿ¶€å...</td>\n",
              "      <td>ur</td>\n",
              "      <td>Urdu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cefcc82292</td>\n",
              "      <td>Ÿáÿ∞ÿß ŸáŸà ŸÖÿß ÿ™ŸÖ ŸÜÿµÿ≠ŸÜÿß ÿ®Ÿá.</td>\n",
              "      <td>ÿπŸÜÿØŸÖÿß Ÿäÿ™ŸÖ ÿ•ÿÆÿ®ÿßÿ±ŸáŸÖ ÿ®ŸÖÿß Ÿäÿ¨ÿ® ÿπŸÑŸäŸáŸÖ ŸÅÿπŸÑŸá ÿå ŸÅÿ¥ŸÑÿ™ ÿßŸÑ...</td>\n",
              "      <td>ar</td>\n",
              "      <td>Arabic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>e98005252c</td>\n",
              "      <td>et cela est en grande partie d√ª au fait que le...</td>\n",
              "      <td>Les m√®res se droguent.</td>\n",
              "      <td>fr</td>\n",
              "      <td>French</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>58518c10ba</td>\n",
              "      <td>‰∏éÂüéÂ∏ÇÂèäÂÖ∂‰ªñÂÖ¨Ê∞ëÂèäÁ§æÂå∫ÁªÑÁªá‰ª£Ë°®Â∞±IMAÁöÑËâ∫ÊúØÂèëÂ±ïËøõË°åÂØπËØù&amp;amp</td>\n",
              "      <td>IMA‰∏éÂÖ∂‰ªñÁªÑÁªáÂêà‰ΩúÔºåÂõ†‰∏∫ÂÆÉ‰ª¨ÈÉΩ‰æùÈù†ÂÖ±‰∫´ËµÑÈáë„ÄÇ</td>\n",
              "      <td>zh</td>\n",
              "      <td>Chinese</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>c32b0d16df</td>\n",
              "      <td>–û–Ω–∞ –≤—Å–µ –µ—â–µ –±—ã–ª–∞ —Ç–∞–º.</td>\n",
              "      <td>–ú—ã –¥—É–º–∞–ª–∏, —á—Ç–æ –æ–Ω–∞ —É—à–ª–∞, –æ–¥–Ω–∞–∫–æ, –æ–Ω–∞ –æ—Å—Ç–∞–ª–∞—Å—å.</td>\n",
              "      <td>ru</td>\n",
              "      <td>Russian</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  ... language\n",
              "0  c6d58c3f69  ...     Urdu\n",
              "1  cefcc82292  ...   Arabic\n",
              "2  e98005252c  ...   French\n",
              "3  58518c10ba  ...  Chinese\n",
              "4  c32b0d16df  ...  Russian\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-gEsFYRNI9uS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "a4d9810a-29dd-4208-cfd2-a7684d4a53b9"
      },
      "source": [
        "#view augmented\n",
        "print(test_aug.shape)\n",
        "test_aug.head()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5195, 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>premise</th>\n",
              "      <th>hypothesis</th>\n",
              "      <th>lang_abv</th>\n",
              "      <th>language</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>c6d58c3f69</td>\n",
              "      <td>ÿ®ÿß⁄©ÿ≥ÿ≤ ⁄©ÿß ŸÜÿßŸÖ ÿ®ÿß⁄©ÿ≥ ÿå ⁄©€åÿ≥€å ÿå ÿ±ÿß⁄Ü€åŸÑ ÿå €åÿ≥ÿπ€åÿß€Å ÿå ⁄©€å...</td>\n",
              "      <td>⁄©ŸàŸÑŸÖ€åŸÜ €Åÿßÿ¶€å ÿßÿ≥⁄©ŸàŸÑ ⁄©€í ÿß€å⁄© ÿ∑ÿßŸÑÿ® ÿπŸÑŸÖ ⁄©€åÿ≥€å ⁄©Ÿà ⁄©Ÿàÿ¶€å...</td>\n",
              "      <td>ur</td>\n",
              "      <td>Urdu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cefcc82292</td>\n",
              "      <td>Ÿáÿ∞ÿß ŸÜÿµÿ≠ ŸÑŸÜÿß.</td>\n",
              "      <td>ÿπŸÜÿØŸÖÿß Ÿäÿ™ŸÖ ÿ•ÿÆÿ®ÿßÿ±ŸÜÿß ÿ®ŸÖÿß Ÿäÿ¨ÿ® ÿßŸÑŸÇŸäÿßŸÖ ÿ®Ÿá ÿå ŸÑÿß ÿ™ÿ≥ŸÖÿ≠ ...</td>\n",
              "      <td>ar</td>\n",
              "      <td>Arabic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>e98005252c</td>\n",
              "      <td>Et la raison la plus probable est due au fait ...</td>\n",
              "      <td>La m√®re se drogue.</td>\n",
              "      <td>fr</td>\n",
              "      <td>French</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>58518c10ba</td>\n",
              "      <td>‰∏éÂüéÂ∏ÇÂèäÂÖ∂‰ªñÂÖ¨Ê∞ëÂèäÁ§æÂå∫ÁªÑÁªá‰ª£Ë°®Â∞±IMAÁöÑËâ∫ÊúØÂèëÂ±ïËøõË°åÂØπËØù&amp;amp</td>\n",
              "      <td>IMA‰∏éÂÖ∂‰ªñÁªÑÁªáÂêà‰ΩúÔºåÂõ†‰∏∫ÂÆÉ‰ª¨ÈÉΩ‰æùÈù†ÂÖ±‰∫´ËµÑÈáë„ÄÇ</td>\n",
              "      <td>zh</td>\n",
              "      <td>Chinese</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>c32b0d16df</td>\n",
              "      <td>–û–Ω–∞ –≤—Å–µ –µ—â–µ –±—ã–ª–∞ —Ç–∞–º.</td>\n",
              "      <td>–ú—ã –¥—É–º–∞–ª–∏, —á—Ç–æ –æ–Ω–∞ —É—à–ª–∞, –Ω–æ –æ–Ω–∞ –æ—Å—Ç–∞–ª–∞—Å—å.</td>\n",
              "      <td>ru</td>\n",
              "      <td>Russian</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  ... language\n",
              "0  c6d58c3f69  ...     Urdu\n",
              "1  cefcc82292  ...   Arabic\n",
              "2  e98005252c  ...   French\n",
              "3  58518c10ba  ...  Chinese\n",
              "4  c32b0d16df  ...  Russian\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "yU3A4jOjI9uU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "5d819765-3329-487b-abd2-c20ca6d03b5c"
      },
      "source": [
        "#view twice augmented\n",
        "print(test_twice_aug.shape)\n",
        "test_twice_aug.head()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5195, 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>premise</th>\n",
              "      <th>hypothesis</th>\n",
              "      <th>lang_abv</th>\n",
              "      <th>language</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>c6d58c3f69</td>\n",
              "      <td>ÿ®ÿß⁄©ÿ≥ÿ≤ ⁄©ÿß ŸÜÿßŸÖ ÿ®ÿß⁄©ÿ≥ ÿå ⁄©€åÿ≥€å ÿå ÿ±ÿß⁄Ü€åŸÑ ÿå €åÿ≥ÿπ€åÿß€Å ÿå ⁄©€å...</td>\n",
              "      <td>⁄©ŸàŸÑŸÖ€åŸÜ €Åÿßÿ¶€å ÿßÿ≥⁄©ŸàŸÑ ⁄©€í ÿß€å⁄© ÿ∑ÿßŸÑÿ® ÿπŸÑŸÖ ⁄©€åÿ≥€å ⁄©Ÿà ⁄©Ÿàÿ¶€å...</td>\n",
              "      <td>ur</td>\n",
              "      <td>Urdu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cefcc82292</td>\n",
              "      <td>ÿ™ŸÖ ŸÜÿµÿ≠ Ÿáÿ∞ÿß ŸÑŸÜÿß.</td>\n",
              "      <td>ÿπŸÜÿØŸÖÿß Ÿäÿ™ŸÖ ÿ•ÿÆÿ®ÿßÿ±ŸÜÿß ÿ®ŸÖÿß Ÿäÿ¨ÿ® ÿßŸÑŸÇŸäÿßŸÖ ÿ®Ÿá ÿå ŸÑÿß ÿ™ÿ≥ŸÖÿ≠ ...</td>\n",
              "      <td>ar</td>\n",
              "      <td>Arabic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>e98005252c</td>\n",
              "      <td>Et la raison possible est que la m√®re prend le...</td>\n",
              "      <td>M√®re prend de la drogue.</td>\n",
              "      <td>fr</td>\n",
              "      <td>French</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>58518c10ba</td>\n",
              "      <td>‰∏éÂüéÂ∏ÇÂèäÂÖ∂‰ªñÂÖ¨Ê∞ëÂèäÁ§æÂå∫ÁªÑÁªá‰ª£Ë°®Â∞±IMAÁöÑËâ∫ÊúØÂèëÂ±ïËøõË°åÂØπËØù&amp;amp</td>\n",
              "      <td>IMA‰∏éÂÖ∂‰ªñÁªÑÁªáÂêà‰ΩúÔºåÂõ†‰∏∫ÂÆÉ‰ª¨ÈÉΩ‰æùÈù†ÂÖ±‰∫´ËµÑÈáë„ÄÇ</td>\n",
              "      <td>zh</td>\n",
              "      <td>Chinese</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>c32b0d16df</td>\n",
              "      <td>–û–Ω–∞ –≤—Å–µ –µ—â–µ –±—ã–ª–∞ —Ç–∞–º.</td>\n",
              "      <td>–ú—ã –¥—É–º–∞–ª–∏, –≤—ã —É–µ–∑–∂–∞–µ—Ç–µ, –Ω–æ –æ–Ω –æ—Å—Ç–∞–ª—Å—è.</td>\n",
              "      <td>ru</td>\n",
              "      <td>Russian</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  ... language\n",
              "0  c6d58c3f69  ...     Urdu\n",
              "1  cefcc82292  ...   Arabic\n",
              "2  e98005252c  ...   French\n",
              "3  58518c10ba  ...  Chinese\n",
              "4  c32b0d16df  ...  Russian\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "0QR7QVmlI9uW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#select relevant columns\n",
        "test_aug_text = test_aug[['premise', 'hypothesis']].values.tolist()\n",
        "test_twice_aug_text = test_twice_aug[['premise', 'hypothesis']].values.tolist()\n",
        "\n",
        "if USE_TTA:\n",
        "    #encode \n",
        "    print('Encoding test dataset(s)...')\n",
        "    test_aug_enc = TOKENIZER.batch_encode_plus(\n",
        "        test_aug_text,\n",
        "        pad_to_max_length = True,\n",
        "        max_length = MAX_LEN\n",
        "    )\n",
        "\n",
        "    #encode\n",
        "    test_twice_aug_enc = TOKENIZER.batch_encode_plus(\n",
        "        test_twice_aug_text,\n",
        "        pad_to_max_length = True,\n",
        "        max_length = MAX_LEN\n",
        "    )\n",
        "\n",
        "    #convert to TPU format\n",
        "    test_aug_ds = (\n",
        "        tf.data.Dataset\n",
        "        .from_tensor_slices(test_aug_enc['input_ids'])\n",
        "    .batch(BATCH_SIZE)\n",
        "    )\n",
        "\n",
        "    #convert to TPU format\n",
        "    test_twice_aug_ds = (\n",
        "        tf.data.Dataset\n",
        "        .from_tensor_slices(test_twice_aug_enc['input_ids'])\n",
        "    .batch(BATCH_SIZE)\n",
        "    )\n",
        "    print('')\n",
        "    print('Done')"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "vfcjwuiaI9uX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#finally, get all predictions\n",
        "preds = RoBERTa.predict(test_ds)\n",
        "\n",
        "if USE_TTA:\n",
        "    preds_aug = RoBERTa.predict(test_aug_ds)\n",
        "    preds_twice_aug = RoBERTa.predict(test_twice_aug_ds)\n",
        "\n",
        "    #and blend predictions equally\n",
        "    blended_preds = (preds + preds_aug + preds_twice_aug)/3"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "xcKewY66K-O1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "35f9f4dd-f240-4872-b0df-3c7ff449a0c3"
      },
      "source": [
        "#create submission dataframe and save\n",
        "submission = pd.DataFrame()\n",
        "submission['id'] = test['id']\n",
        "\n",
        "if USE_TTA:\n",
        "    #choose blended predictions as final predictions\n",
        "    submission['prediction'] = blended_preds.argmax(axis = 1)\n",
        "\n",
        "else:\n",
        "    #choose predictions on reg test set as final predictions\n",
        "    submission['prediction'] = preds.argmax(axis = 1)\n",
        "\n",
        "#sanity check\n",
        "submission.head(10)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>c6d58c3f69</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cefcc82292</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>e98005252c</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>58518c10ba</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>c32b0d16df</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>aa2510d454</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>865d1c7b16</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>a16f7ed56b</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>6d9fa191e6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>c156e8fed5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  prediction\n",
              "0  c6d58c3f69           2\n",
              "1  cefcc82292           2\n",
              "2  e98005252c           0\n",
              "3  58518c10ba           1\n",
              "4  c32b0d16df           1\n",
              "5  aa2510d454           0\n",
              "6  865d1c7b16           1\n",
              "7  a16f7ed56b           0\n",
              "8  6d9fa191e6           1\n",
              "9  c156e8fed5           1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Pr2u81IAI9ub",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "463f265c-296b-46dd-b944-472ef82ce1e2"
      },
      "source": [
        "submission.to_csv('submission.csv', index = False)\n",
        "print('Submission saved')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Submission saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "trusted": true,
        "id": "8BRe-53OK-O4",
        "colab_type": "text"
      },
      "source": [
        "**As this is a new getting started competition, this notebook is a work in progress that I will continually update as the competition grows. If you have any questions/suggestions, please leave them below. Stay tuned for more!**"
      ]
    }
  ]
}